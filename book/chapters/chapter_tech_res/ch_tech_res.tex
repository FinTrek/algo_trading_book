% !TEX root = ../../book.tex
%\hfill
%\par\vspace{\baselineskip}

\chapter{The Research Stack}\label{chap:ch_tech_res}
Designing, testing, calibrating, measuring and improving a suite of algorithmic trading strategy is not for the faint of heart. As we have  seen It's a large scale problem that requires a deep investment and can take years to setup. One of the critical component of the overall stack and one that is often underfunded and thus underdeveloped is the research environment. For an execution business this is most often an afterthought, a setup that is scrounged together from existing piece of the infrastructure they already know the need to operate: historical market data, reference data, and historical transactional data in order to fulfill the TCA needs of the clients and a quantitative team often has to do with what is available. \\

Their needs and requirements take a back seat to the needs of the client even if in the end what the client needs is Algo performance not necessarily providing performance reports on  performance that is sub-optimal due to lack of a decent research environment. The shrewd reader will likely notice some animosity in this tirade. Must come from the years of frustration! Things though are getting better and nowadays quantitative teams a much better funded and resourced, often even with dedicated infrastructure and resources to support and maintain their research environment.\\

In this chapter we'll try to provide some pointers of what a best-in-class research stack would look like. The basic components, approaches and considerations born out two decade+  of experience and the trials and tribulations (mostly tribulations!) of yours truly. While most of the chapter is reserved to the ``standard" setup of an execution business we'll reserve, where appropriate, a short paragraph to describe the setup most often found in an HFT setup as it is quite different and has some interesting features worth at least mentioning.\\


The authors wish they could dedicate the equivalent of a full book (and maybe one day they will) to this topic. Unfortunately the book is already very long and our Editor would love to see this book published before retirement so we are forced to restrain our desire and provide only a brief overview of the topic.  

\section{Data Infrastructure}
Without data there is no research. Period. I then goes without saying then that the most important component of your research environment must be your data infrastructure. There are two main parts of a typical data infrastructure: Historical Market Data, and Historical Transactional Data. \\

Additionally we  should not forget the lessons from chapter~\ref{chap:ch_trading_fund} thus we should make sure we have access to historical reference data as well. While most of the research and analytics will be intro-day and thus less dependent of historical consistency of reference data it is sometime necessary to look at prices/volumes over multiple days which creates the added complexity of potentially having to adjust the data for corporate actions. This is not a simple thing and rarely reference data platform store all ticker changes history, symbology mapping and the various corporate action multipliers needed to adjust the data.

\subsection{Ticker Plant}
Market data, just as the case was for the production tech stack can be the most challenging and expensive component of a data infrastructure. Even for  the simplest usecase: consolidated Level 1 quote and trade data TAQ data from NYSE \footnote{\url{http://www.nyxdata.com/data-products/daily-taq}} at present time charges \$3000 per month of history It is more than 18Gb per day compressed. Any respectable operation needs at least one to two years so just the simplest setup requires an investments of >\$75,000 and storage and processing capacity for 8Tb of data. A more serious setup would have Level 2 data for the top exchanges with costs and sizes several multiples  of what quoted before. \\
Once collected the data has to be processed, normalized and stored in an infrastructure that allows analysis and processing. While theoretically one could store this data in a Relational Database realistically this never creates a usable infrastructure and historically only few vendor infrastructures have been successful in this space. Notably KDB from Kx System \footnote{\url{https://kx.com/}} has been the dominant player in the space despite the steep cost and the very terse and cryptic q language that is a hard to master and thus a very sought after skill \footnote{Some people will argue that q is the reason for kdb success. The jury is out on that}. In recent years this space has evolved significantly and there are now very powerful open-source contenders like InfluxDB \footnote{\url{https://www.influxdata.com/}} and many others. Others have started exploring distributed systems on top of the Hadoop/Spark ecosystem. KDB continues to maintain it's dominance in large scale trading operations but its reign is no longer as certain it used to be.\\

The best setups also collect and provide, through a similar API, intraday real-time market data. This allows a lot of the analysis tools to work both historically and intraday. Since it's quite hard to capture with 100\% accuracy the data at all times very often the intraday data is discarded overnight and replaced with the vendor provided official one that has been processed and adjusted for the various erroneous trade events etc. 

\paragraph{HFT Setup}

Ultra-low latency HFT trading operations usually capture and store the network packets from the raw production exchange feeds for all major exchanges not once but for each data center. This is to be able to train separately the strategy in each data center and seeing the market data from other data centers with the actual delays as the strategy would see in production. Data is kept in a non processed compressed format without the leverage of any time series database. The size of this data is staggering, in the order of >50g compressed per day per data center.

\subsection{Historical Transactional Data}
This is another complicated and large infrastructure problem. Ideally all OMS order and trading events should be stored in a time series db as they happen and then processed and store in a consistent data model. When we were discussing OMS in chapter \ref{chap:ch_tech} we mentioned that it often leverages a bus based infrastructure. One of the important usecases for that is exactly so that a gateway process can listen to all these events and insert them into the trasactional db.\\
Similar considerations around vendors and solutions apply and KDB is still a strong contender for these systems but not as dominant as in the market data domain. This is somewhat surprising since, as we will see, a lot of the model calibration and TCA environments we'll discuss in a future sections require the joining and time alignment of both market data and transactional data (the so called asof and windows joins) that are one of the absolute strengths of KDB.

\section{Calibration infrastructure}
\section{Simulation Environment}
\section{TCA Environment}

